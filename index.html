<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Local ML Training Platform</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tensorflow/4.10.0/tf.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.1/jszip.min.js"></script>
    <style>
        /* CSS Styles (mostly unchanged, keeping it concise for brevity) */
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; color: #333; }
        .container { max-width: 1200px; margin: 0 auto; padding: 20px; }
        .header { text-align: center; color: white; margin-bottom: 30px; }
        .header h1 { font-size: 2.5rem; margin-bottom: 10px; text-shadow: 2px 2px 4px rgba(0,0,0,0.3); }
        .tabs { display: flex; background: rgba(255,255,255,0.1); border-radius: 15px; padding: 5px; margin-bottom: 30px; backdrop-filter: blur(10px); }
        .tab { flex: 1; padding: 15px; text-align: center; border-radius: 10px; cursor: pointer; color: white; font-weight: 600; transition: all 0.3s ease; }
        .tab.active { background: rgba(255,255,255,0.2); box-shadow: 0 4px 15px rgba(0,0,0,0.1); }
        .tab-content { display: none; background: white; border-radius: 20px; padding: 30px; box-shadow: 0 20px 40px rgba(0,0,0,0.1); backdrop-filter: blur(20px); }
        .tab-content.active { display: block; animation: fadeIn 0.5s ease; }
        @keyframes fadeIn { from { opacity: 0; transform: translateY(20px); } to { opacity: 1; transform: translateY(0); } }
        .file-upload-area { margin-bottom: 20px; }
        .file-upload { border: 3px dashed #667eea; border-radius: 15px; padding: 20px; text-align: center; cursor: pointer; transition: all 0.3s ease; margin-bottom: 10px; }
        .file-upload:hover { border-color: #764ba2; background: rgba(102, 126, 234, 0.05); }
        .file-upload.dragover { background: rgba(102, 126, 234, 0.1); border-color: #764ba2; }
        .file-upload p { font-size: 0.9em; color: #555; }
        .btn { background: linear-gradient(45deg, #667eea, #764ba2); color: white; border: none; padding: 12px 25px; border-radius: 25px; cursor: pointer; font-weight: 600; transition: all 0.3s ease; margin: 5px; }
        .btn:hover { transform: translateY(-2px); box-shadow: 0 10px 20px rgba(0,0,0,0.2); }
        .btn:disabled { opacity: 0.5; cursor: not-allowed; transform: none; }
        .image-grid { display: grid; grid-template-columns: repeat(auto-fill, minmax(200px, 1fr)); gap: 20px; margin-top: 20px; }
        .image-item { border: 2px solid #e0e0e0; border-radius: 10px; overflow: hidden; transition: all 0.3s ease; background: white; position: relative; }
        .annotation-count-badge { position: absolute; top: 5px; right: 5px; background-color: rgba(102, 126, 234, 0.8); color: white; padding: 3px 7px; border-radius: 10px; font-size: 0.8em; font-weight: bold; }
        .image-item:hover { transform: translateY(-5px); box-shadow: 0 10px 20px rgba(0,0,0,0.1); }
        .image-item img { width: 100%; height: 150px; object-fit: cover; }
        .image-controls { padding: 15px; text-align: center; }
        .progress-bar { width: 100%; height: 20px; background: #e0e0e0; border-radius: 10px; overflow: hidden; margin: 20px 0; }
        .progress-fill { height: 100%; background: linear-gradient(45deg, #667eea, #764ba2); width: 0%; transition: width 0.3s ease; }
        .model-info { background: #f8f9fa; padding: 20px; border-radius: 10px; margin: 20px 0; }
        .log { background: #1e1e1e; color: #00dd00; padding: 15px; border-radius: 10px; height: 250px; overflow-y: auto; font-family: monospace; font-size: 0.9em; margin-top: 20px; white-space: pre-wrap; }
        .log p { margin-bottom: 3px; line-height: 1.3; }
        .stats { display: grid; grid-template-columns: repeat(auto-fit, minmax(180px, 1fr)); gap: 20px; margin: 20px 0; }
        .stat-card { background: linear-gradient(135deg, #667eea, #764ba2); color: white; padding: 20px; border-radius: 15px; text-align: center; }
        .stat-value { font-size: 2rem; font-weight: bold; margin-bottom: 5px; }
        .canvas-container { position: relative; display: inline-block; margin: 10px; max-width: 100%; }
        .annotation-canvas { border: 2px solid #667eea; cursor: crosshair; display: block; max-width: 100%; height: auto; }
        .loss-breakdown span { margin-right: 15px; }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ü§ñ Local ML Training Platform</h1>
            <p>Train your models locally without any installations - Roboflow alternative that runs in your browser!</p>
        </div>

        <div class="tabs">
            <div class="tab active" onclick="switchTab(event, 'dataset')">üìÅ Dataset</div>
            <div class="tab" onclick="switchTab(event, 'labeling')">üè∑Ô∏è Labeling</div>
            <div class="tab" onclick="switchTab(event, 'training')">üß† Training</div>
            <div class="tab" onclick="switchTab(event, 'export')">üì§ Export</div>
        </div>

        <!-- Dataset Tab -->
        <div id="dataset" class="tab-content active">
            <h2>üìÅ Dataset Management</h2>
            <div class="file-upload-area">
                <div class="file-upload" id="combinedFileUpload">
                    <h3>Drop Images, Annotation Files (YOLO .txt, COCO .json), or Roboflow ZIP files here</h3>
                    <p>Supports: JPG, PNG, GIF, WEBP, TXT, JSON, ZIP</p>
                    <p>For ZIPs, ensure images and annotations (labels/ subfolder) are present.</p>
                    <input type="file" id="combinedFileInput" multiple accept="image/*,.txt,.json,.zip" style="display: none;">
                </div>
            </div>
             <div class="stats" id="datasetStats">
                <div class="stat-card"><div class="stat-value" id="totalImages">0</div><div>Total Images</div></div>
                <div class="stat-card"><div class="stat-value" id="labeledImages">0</div><div>Images with Annotations</div></div>
                <div class="stat-card"><div class="stat-value" id="totalAnnotations">0</div><div>Total Bounding Boxes</div></div>
                <div class="stat-card"><div class="stat-value" id="uniqueClasses">0</div><div>Unique Classes</div></div>
            </div>
            <div class="image-grid" id="imageGrid"></div>
        </div>

        <!-- Labeling Tab -->
        <div id="labeling" class="tab-content">
            <h2>üè∑Ô∏è Image Labeling</h2>
            <div class="model-info">
                <p><strong>Instructions:</strong> Click and drag to create bounding boxes. Enter labels. Or upload annotations in Dataset tab.</p>
                <button class="btn" onclick="nextImage()">Next Image (‚Üí)</button>
                <button class="btn" onclick="prevImage()">Previous Image (‚Üê)</button>
                <button class="btn" onclick="clearAnnotations()">Clear Current Image Annotations</button>
            </div>
            <div id="labelingArea" style="text-align: center;">
                <div class="canvas-container"><canvas id="labelingCanvas" class="annotation-canvas" width="800" height="600"></canvas></div>
            </div>
        </div>

        <!-- Training Tab -->
        <div id="training" class="tab-content">
             <h2>üß† Model Training</h2>
            <div class="model-info">
                <h3>Training Configuration</h3>
                <label for="modelType">Model Type:</label>
                <select id="modelType" onchange="updateTrainingUI()">
                    <option value="classification">Image Classification</option>
                    <option value="detection" selected>Object Detection</option>
                </select>
                <br><br>
                <label for="epochs">Epochs:</label>
                <input type="number" id="epochs" value="20" min="1" max="500">
                <br><br>
                <label for="learningRate">Learning Rate:</label>
                <input type="number" id="learningRate" value="0.001" step="0.0001" min="0.00001" max="0.1">
                <br><br>
                <div id="batchSizeConfig" style="display: none;"> 
                    <label for="batchSize">Batch Size:</label>
                    <input type="number" id="batchSize" value="4" min="1" max="32">
                    <br><br>
                </div>
                <button class="btn" onclick="startTraining()" id="trainBtn">üöÄ Start Training</button>
                <button class="btn" onclick="stopTraining()" id="stopBtn" disabled>‚èπÔ∏è Stop Training</button>
            </div>

            <div class="progress-bar"><div class="progress-fill" id="trainingProgress"></div></div>

            <div class="stats" id="trainingStats">
                <div class="stat-card"><div class="stat-value" id="currentEpoch">0</div><div>Current Epoch</div></div>
                <div class="stat-card">
                    <div class="stat-value" id="trainingLoss">0.00</div>
                    <div>Total Loss</div>
                    <div id="lossBreakdownDisplay" style="font-size: 0.8em; margin-top: 5px; display:none;">
                        <span id="locLossDisplay">Loc: 0.00</span>
                        <span id="classLossDisplay">Class: 0.00</span>
                    </div>
                </div>
                <div class="stat-card">
                    <div class="stat-value" id="accuracy">0.00%</div>
                    <div id="accuracyLabel">Accuracy (Metric)</div>
                </div>
            </div>
            <div class="log" id="trainingLog"></div>
        </div>

        <!-- Export Tab -->
        <div id="export" class="tab-content">
             <h2>üì§ Export Model</h2>
            <div class="model-info">
                <h3>Export Options</h3>
                <button class="btn" onclick="exportModel('tensorflow')">üì¶ Export TensorFlow.js</button>
                <button class="btn" onclick="exportModel('weights')">‚öñÔ∏è Export Weights Only</button>
                <button class="btn" onclick="exportModel('onnx')">üîÑ Export ONNX (Simulated)</button>
                <button class="btn" onclick="exportDataset()">üìä Export Labeled Dataset (JSON)</button>
            </div>
            <div id="exportStatus"></div>
        </div>
    </div>

    <script>
        // Global variables and JSZip check
        let images = []; 
        let currentImageIndex = 0;
        let model = null;
        let isTraining = false;
        let classMap = {}; 
        let nextClassId = 0;
        const IMG_WIDTH = 224; 
        const IMG_HEIGHT = 224;

        if (typeof JSZip === 'undefined') {
            alert("JSZip library not loaded. ZIP file processing will not work. Please check your internet connection or the JSZip CDN link.");
        }
        // --- Dataset Management, Labeling System (mostly same as your v3/v4/v5) ---
        // For brevity, this section will be heavily condensed. The actual implementation is assumed from previous versions.
        const combinedFileUpload=document.getElementById('combinedFileUpload'),combinedFileInput=document.getElementById('combinedFileInput');combinedFileUpload.addEventListener('click',()=>combinedFileInput.click());combinedFileUpload.addEventListener('dragover',e=>handleDragOver(e,combinedFileUpload));combinedFileUpload.addEventListener('dragleave',e=>handleDragLeave(e,combinedFileUpload));combinedFileUpload.addEventListener('drop',handleCombinedDrop);combinedFileInput.addEventListener('change',handleCombinedFileSelect);function handleDragOver(e,el){e.preventDefault();el.classList.add('dragover');}
        function handleDragLeave(e,el){el.classList.remove('dragover');}
        async function handleCombinedDrop(e){e.preventDefault();combinedFileUpload.classList.remove('dragover');await processCombinedFiles(Array.from(e.dataTransfer.files));}
        async function handleCombinedFileSelect(e){await processCombinedFiles(Array.from(e.target.files));}
        async function processCombinedFiles(files){log("Processing uploaded files...");const iF=[],yF=[],cF=[],zF=[];for(const f of files)
        {if(f.type.startsWith('image/'))iF.push(f);else if(f.name.endsWith('.txt'))yF.push(f);else if(f.name.endsWith('.json'))cF.push(f);else if(f.name.endsWith('.zip'))zF.push(f);else log(`‚ö†Ô∏è Unsupported: ${f.name}`);}
        for(const z of zF)await processZipFile(z);if(iF.length>0)await processImageFiles(iF);if(yF.length>0)await processAnnotationFiles(yF,'yolo');if(cF.length>0)await processAnnotationFiles(cF,'coco');updateDatasetStats();renderImageGrid();if(images.length>0&¬§tImageIndex>=images.length)currentImageIndex=0;if(images.length>0)loadImageForLabeling();}
        async function processZipFile(zipFile){log(`‚öôÔ∏è ZIP: ${zipFile.name}`);const jszip=new JSZip(),zip=await jszip.loadAsync(zipFile);const iFZ=[],yFZ=[];let cFZ=null;for(const p in zip.files){const fE=zip.files[p];if(!fE.dir){const fN=p.split('/').pop(),e=fN.split('.').pop().toLowerCase();
        if(['jpg','jpeg','png','webp'].includes(e))iFZ.push(new File([await fE.async('blob')],fN));else if(e==='txt')yFZ.push({name:fN,content:await fE.async('string')});else if(fN.endsWith('.coco.json')||fN==='annotations.json'||p.toLowerCase().includes('_annotations.coco.json'))cFZ={name:fN,content:await fE.async('string'), path: p};}} // Store path for context
        if(iFZ.length>0){log(`Found ${iFZ.length} images in ZIP.`); await processImageFiles(iFZ);} else {log("No image files found in ZIP.");}
        if(cFZ){log(`Processing COCO JSON from ZIP: ${cFZ.path}`);await parseCocoJsonAnnotations(cFZ.content);}else if(yFZ.length>0){log(`Processing ${yFZ.length} YOLO TXT from ZIP...`);for(const y of yFZ){const iNP=y.name.replace(/\.[^/.]+$/,"");const tI=images.find(i=>i.name.startsWith(iNP+'.'));if(tI)parseYoloTxtAnnotations(y.content,tI);else log(`‚ö†Ô∏è No match for YOLO ${y.name}`);}}else{log("No COCO/YOLO annotations found in ZIP.");}log(`‚úÖ ZIP ${zipFile.name} done.`);}
        async function processImageFiles(files){for(const f of files){if(images.find(i=>i.id===f.name))continue;const r=new FileReader();await new Promise(res=>{r.onload=eR=>{const tI=new Image();tI.onload=()=>{images.push({id:f.name,name:f.name,src:eR.target.result,annotations:[],originalWidth:tI.width,originalHeight:tI.height,tensor:null});res();};tI.onerror=()=>{log(`Error loading image ${f.name} to get dimensions.`);res();};tI.src=eR.target.result;};r.onerror=()=>{log(`Error reading file ${f.name}`);res();};r.readAsDataURL(f);});}}
        async function processAnnotationFiles(files,format){for(const f of files){const r=new FileReader();await new Promise(res=>{r.onload=eR=>{const c=eR.target.result;if(format==='yolo'){const iNP=f.name.replace(/\.[^/.]+$/,"");const tI=images.find(i=>i.name.startsWith(iNP+'.'));if(tI)parseYoloTxtAnnotations(c,tI);else log(`‚ö†Ô∏è No match for YOLO TXT: ${f.name}`);}else if(format==='coco')parseCocoJsonAnnotations(c);res();};r.readAsText(f);});}}
        function parseYoloTxtAnnotations(txt,imgObj){if(!imgObj){log("‚ö†Ô∏è parseYoloTxtAnnotations: imageObject is null."); return;} imgObj.annotations=[];txt.trim().split('\n').forEach(l=>{const p=l.trim().split(' ');if(p.length!==5)return;const cId=parseInt(p[0]);let lab=`class_${cId}`;for(const cn in classMap)if(classMap[cn]===cId)lab=cn;if(!Object.values(classMap).includes(cId)&&!classMap[lab])classMap[lab]=cId;if(cId>=nextClassId)nextClassId=cId+1;const w=parseFloat(p[3])*imgObj.originalWidth,h=parseFloat(p[4])*imgObj.originalHeight,x=parseFloat(p[1])*imgObj.originalWidth-w/2,y=parseFloat(p[2])*imgObj.originalHeight-h/2;imgObj.annotations.push({x,y,width:w,height:h,label:lab,classId:cId});});}
        
        // MODIFIED parseCocoJsonAnnotations with more logging
        function parseCocoJsonAnnotations(jsonContent) {
            try {
                const cocoData = JSON.parse(jsonContent);
                log(`üîç Parsing COCO JSON: File contains ${cocoData.images?.length || 0} image entries, ${cocoData.annotations?.length || 0} annotation entries, ${cocoData.categories?.length || 0} categories.`);
                
                let localCocoCategories = {}; // category_id from THIS coco file to its name
                if (cocoData.categories && Array.isArray(cocoData.categories)) {
                    cocoData.categories.forEach(category => {
                        localCocoCategories[category.id] = category.name;
                        // Update global classMap: if class name not present, add it. If present but different ID, log warning.
                        if (!(category.name in classMap)) {
                            classMap[category.name] = category.id; // Prefer COCO ID if it's the first time seeing this class name
                            if (category.id >= nextClassId) nextClassId = category.id + 1;
                        } else if (classMap[category.name] !== category.id) {
                            log(`‚ö†Ô∏è Class "${category.name}" ID conflict: Global map has ID ${classMap[category.name]}, COCO JSON has ID ${category.id}. Using global map ID.`);
                        }
                    });
                    log(`Updated global classMap. Total unique classes now: ${Object.keys(classMap).length}`);
                } else {
                    log("‚ö†Ô∏è COCO JSON has no 'categories' array. Annotation labels might be missing or use raw class IDs.");
                }

                let foundAndAnnotatedCount = 0;
                let imagesInJsonCount = 0;
                if (cocoData.images && Array.isArray(cocoData.images)) {
                    imagesInJsonCount = cocoData.images.length;
                    cocoData.images.forEach(cocoImageEntry => {
                        let imageObject = images.find(img => img.name === cocoImageEntry.file_name);
                        
                        if (!imageObject) {
                            // log(`   - Image "${cocoImageEntry.file_name}" (ID: ${cocoImageEntry.id}) from COCO JSON not found in currently loaded images. Skipping.`);
                            return; 
                        }

                        if (cocoImageEntry.width && cocoImageEntry.height) {
                            imageObject.originalWidth = cocoImageEntry.width;
                            imageObject.originalHeight = cocoImageEntry.height;
                        }
                        
                        imageObject.annotations = []; // Clear previous annotations for this image
                        let annotationsForThisImageCount = 0;

                        if (cocoData.annotations && Array.isArray(cocoData.annotations)) {
                            cocoData.annotations
                                .filter(ann => ann.image_id === cocoImageEntry.id)
                                .forEach(cocoAnn => {
                                    const [x, y, width, height] = cocoAnn.bbox;
                                    let categoryName = `class_${cocoAnn.category_id}`; // Default
                                    if (localCocoCategories[cocoAnn.category_id]) {
                                        categoryName = localCocoCategories[cocoAnn.category_id];
                                    } else { // Fallback to check global map if category not in this COCO's categories section
                                        for (const nameInMap in classMap) {
                                            if (classMap[nameInMap] === cocoAnn.category_id) { categoryName = nameInMap; break; }
                                        }
                                        if (categoryName === `class_${cocoAnn.category_id}`) { // Still not found by ID
                                            log(`‚ö†Ô∏è Cat ID ${cocoAnn.category_id} for ann in "${cocoImageEntry.file_name}" not in COCO cats or global map. Using generic label.`);
                                            if (!classMap[categoryName]) { classMap[categoryName] = cocoAnn.category_id; if (cocoAnn.category_id >= nextClassId) nextClassId = cocoAnn.category_id + 1;}
                                        }
                                    }
                                    
                                    imageObject.annotations.push({
                                        x: x, y: y, width: width, height: height,
                                        label: categoryName, classId: classMap[categoryName]
                                    });
                                    annotationsForThisImageCount++;
                                });
                        }
                        if (annotationsForThisImageCount > 0) {
                            foundAndAnnotatedCount++;
                        }
                    });
                    log(`‚úÖ COCO JSON: Matched and annotated ${foundAndAnnotatedCount} images out of ${imagesInJsonCount} listed in the JSON.`);
                } else {
                     log("‚ö†Ô∏è COCO JSON has no 'images' array. Cannot map annotations.");
                }

            } catch (error) {
                log(`‚ùå Error parsing COCO JSON: ${error.message}`); console.error("COCO Parse Error:", error);
            }
        }
        function updateDatasetStats(){const lIC=images.filter(i=>i.annotations?.length>0).length,tB=images.reduce((s,i)=>s+(i.annotations?.length||0),0),uC=new Set(Object.keys(classMap));document.getElementById('totalImages').textContent=images.length;document.getElementById('labeledImages').textContent=lIC;document.getElementById('totalAnnotations').textContent=tB;document.getElementById('uniqueClasses').textContent=uC.size;}
        function renderImageGrid(){const g=document.getElementById('imageGrid');g.innerHTML='';images.forEach((i,idx)=>{const it=document.createElement('div');it.className='image-item';let b=i.annotations?.length>0?`<span class="annotation-count-badge">${i.annotations.length}</span>`:'';it.innerHTML=`<img src="${i.src}" alt="${i.name}" title="${i.name}">${b}<div class="image-controls"><button class="btn" onclick="setCurrentImage(${idx})">Label/View</button><button class="btn" onclick="removeImage(${idx})">Remove</button></div>`;g.appendChild(it);});}
        function removeImage(idx){if(idx>=0&&idx<images.length){log(`Removed ${images[idx].name}`);images.splice(idx,1);updateDatasetStats();renderImageGrid();if(currentImageIndex>=images.length&&images.length>0)currentImageIndex=images.length-1;if(images.length===0){currentImageIndex=0;loadImageForLabeling();}else if(idx===currentImageIndex||currentImageIndex>=images.length)loadImageForLabeling();}}
        const canvas=document.getElementById('labelingCanvas'),ctx=canvas.getContext('2d');let isDrawing=!1,startX,startY,currentImgElement=null;canvas.addEventListener('mousedown',handleCanvasMouseDown);canvas.addEventListener('mousemove',handleCanvasMouseMove);canvas.addEventListener('mouseup',handleCanvasMouseUp);
        function setCurrentImage(idx){if(idx>=0&&idx<images.length){currentImageIndex=idx;switchTab(null,'labeling');loadImageForLabeling();}else if(images.length===0){currentImageIndex=0;switchTab(null,'labeling');loadImageForLabeling();}}
        function loadImageForLabeling(){if(images.length===0||!images[currentImageIndex]){ctx.clearRect(0,0,canvas.width,canvas.height);ctx.textAlign='center';ctx.fillText("No image.",canvas.width/2,canvas.height/2);currentImgElement=null;return;} const iD=images[currentImageIndex];if(!iD||!iD.src){log(`Err: imgData missing at index ${currentImageIndex}`);return;} currentImgElement=new Image();currentImgElement.onload=()=>{const p=canvas.parentElement,mW=p.clientWidth-20,mH=500;let w=currentImgElement.naturalWidth,h=currentImgElement.naturalHeight,r=w/h;if(w>mW){w=mW;h=w/r;}if(h>mH){h=mH;w=h*r;}canvas.width=w;canvas.height=h;redrawCanvas();};currentImgElement.onerror=()=>{log(`Error loading image for labeling: ${iD.name}`);ctx.clearRect(0,0,canvas.width,canvas.height);ctx.fillText(`Error loading: ${iD.name}`,10,50);currentImgElement=null;};currentImgElement.src=iD.src;}
        function redrawCanvas(){if(!canvas||!ctx)return;ctx.clearRect(0,0,canvas.width,canvas.height);if(!currentImgElement||!currentImgElement.complete||currentImgElement.naturalWidth===0)return;ctx.drawImage(currentImgElement,0,0,canvas.width,canvas.height);const iD=images[currentImageIndex];if(iD?.annotations&&iD.originalWidth){const sX=canvas.width/iD.originalWidth,sY=canvas.height/iD.originalHeight;iD.annotations.forEach(a=>drawBoundingBox(a.x*sX,a.y*sY,a.width*sX,a.height*sY,a.label));}}
        function handleCanvasMouseDown(e){if(!currentImgElement)return;isDrawing=!0;const r=canvas.getBoundingClientRect();startX=e.clientX-r.left;startY=e.clientY-r.top;}
        function handleCanvasMouseMove(e){if(!isDrawing||!currentImgElement)return;const r=canvas.getBoundingClientRect(),cX=e.clientX-r.left,cY=e.clientY-r.top;redrawCanvas();drawBoundingBox(startX,startY,cX-startX,cY-startY,'Drawing...');}
        function handleCanvasMouseUp(e){if(!isDrawing||!currentImgElement)return;isDrawing=!1;const r=canvas.getBoundingClientRect(),eX=e.clientX-r.left,eY=e.clientY-r.top;const cW=eX-startX,cH=eY-startY;if(Math.abs(cW)<5||Math.abs(cH)<5){redrawCanvas();return;} const l=prompt('Label:');if(l&&l.trim()!==""){const iD=images[currentImageIndex];if(!iD.originalWidth){redrawCanvas();return;}const sX=iD.originalWidth/canvas.width,sY=iD.originalHeight/canvas.height;const oX=Math.min(startX,eX)*sX,oY=Math.min(startY,eY)*sY,oW=Math.abs(cW)*sX,oH=Math.abs(cH)*sY;const nA={x:oX,y:oY,width:oW,height:oH,label:l.trim()};iD.annotations.push(nA);const tL=l.trim();if(!(tL in classMap))classMap[tL]=nextClassId++;nA.classId=classMap[tL];updateDatasetStats();redrawCanvas();}else redrawCanvas();}
        function drawBoundingBox(x,y,w,h,l){ctx.strokeStyle='#667eea';ctx.lineWidth=2;ctx.strokeRect(x,y,w,h);ctx.fillStyle='#667eea';ctx.globalAlpha=0.7;const tM=ctx.measureText(l),tW=Math.max(30,tM.width+10),tH=20;ctx.fillRect(x,y-tH,tW,tH);ctx.globalAlpha=1.0;ctx.fillStyle='#fff';ctx.font='14px Segoe UI';ctx.textBaseline='middle';ctx.fillText(l,x+5,y-(tH/2));}
        function nextImage(){if(images.length===0)return;currentImageIndex=(currentImageIndex+1)%images.length;loadImageForLabeling();}
        function prevImage(){if(images.length===0)return;currentImageIndex=(currentImageIndex-1+images.length)%images.length;loadImageForLabeling();}
        function clearAnnotations(){if(images.length>0&&images[currentImageIndex]?.annotations){images[currentImageIndex].annotations=[];redrawCanvas();updateDatasetStats();log(`Annotations cleared for ${images[currentImageIndex].name}`);}}
        function updateTrainingUI(){const mT=document.getElementById('modelType').value,bsC=document.getElementById('batchSizeConfig'),acL=document.getElementById('accuracyLabel'),lBD=document.getElementById('lossBreakdownDisplay');if(mT==='detection'){bsC.style.display='block';acL.textContent='Avg Loss';lBD.style.display='block';}else{bsC.style.display='none';acL.textContent='Accuracy';lBD.style.display='none';}}
        document.addEventListener('DOMContentLoaded',updateTrainingUI);

        async function startTraining() {
            if (images.length === 0) { alert('Please upload dataset!'); return; }
            const imagesWithAnn = images.filter(img => img.annotations && img.annotations.length > 0);
            if (imagesWithAnn.length === 0) { alert('Please annotate images or upload annotations!'); return; }

            isTraining = true;
            document.getElementById('trainBtn').disabled = true;
            document.getElementById('stopBtn').disabled = false;
            log('üöÄ Training session started...');

            const modelType = document.getElementById('modelType').value;
            const epochs = parseInt(document.getElementById('epochs').value);
            const learningRate = parseFloat(document.getElementById('learningRate').value);
            const batchSize = modelType === 'detection' ? parseInt(document.getElementById('batchSize').value) : 8;

            classMap = {}; nextClassId = 0;
            const uniqueLabelSet = new Set();
            imagesWithAnn.forEach(img => img.annotations.forEach(ann => {
                const labelStr = String(ann.label).trim();
                if (labelStr) uniqueLabelSet.add(labelStr);
            }));
            Array.from(uniqueLabelSet).sort().forEach(label => { if (!(label in classMap)) classMap[label] = nextClassId++; });
            
            const numActualClasses = Object.keys(classMap).length;
            log(`Model Type: ${modelType}, Epochs: ${epochs}, LR: ${learningRate}, Batch: ${batchSize}`);
            log(`Training with ${imagesWithAnn.length} annotated images and ${numActualClasses} unique classes found.`);

            let modelOutputDimensionForClasses = numActualClasses;
            if (numActualClasses === 0 && (modelType === 'classification' || modelType === 'detection')) {
                 alert("No valid classes found in annotations. Cannot start training.");
                 stopTraining(); return;
            }
            if (numActualClasses === 1 && (modelType === 'classification' || modelType === 'detection')) {
                log("‚ö†Ô∏è Only 1 unique class. Setting model output dimension for classes to 2 for compatibility.");
                modelOutputDimensionForClasses = 2; 
            }
            log(`Effective model output dimension for classes: ${modelOutputDimensionForClasses}`);
            log(`Class Map: ${JSON.stringify(classMap)}`);

            try {
                tf.dispose(model); model = null;
                if (modelType === 'classification') {
                    await trainClassificationModel(epochs, learningRate, batchSize, imagesWithAnn, modelOutputDimensionForClasses);
                } else { 
                    await trainSimpleDetectionModel(epochs, learningRate, batchSize, imagesWithAnn, modelOutputDimensionForClasses);
                }
            } catch (error) {
                log(`‚ùå Training Error: ${error.message}`); console.error("Training error details:", error);
            } finally {
                isTraining = false; 
                document.getElementById('trainBtn').disabled = false;
                document.getElementById('stopBtn').disabled = true;
                log(model && model.stopTraining ? '‚èπÔ∏è Training stopped by user.' : 'üèÅ Training session ended.');
            }
        }
        
        async function trainClassificationModel(epochs,learningRate,batchSize,trainingImages,numModelOutputClasses){log('üîß Building classification model...');model=tf.sequential();model.add(tf.layers.conv2d({inputShape:[IMG_HEIGHT,IMG_WIDTH,3],filters:16,kernelSize:3,activation:'relu',padding:'same'}));model.add(tf.layers.maxPooling2d({poolSize:2}));model.add(tf.layers.conv2d({filters:32,kernelSize:3,activation:'relu',padding:'same'}));model.add(tf.layers.maxPooling2d({poolSize:2}));model.add(tf.layers.conv2d({filters:64,kernelSize:3,activation:'relu',padding:'same'}));model.add(tf.layers.maxPooling2d({poolSize:2}));model.add(tf.layers.flatten());model.add(tf.layers.dense({units:128,activation:'relu'}));model.add(tf.layers.dropout({rate:0.3}));model.add(tf.layers.dense({units:numModelOutputClasses,activation:'softmax'}));model.compile({optimizer:tf.train.adam(learningRate),loss:'categoricalCrossentropy',metrics:['accuracy']});log('üìä Preparing classification data...');const{xs,ys}=await prepareClassificationData(trainingImages,numModelOutputClasses);if(!xs||!ys){log("Failed to prepare classification data.");return;}
        log(`Data shapes: xs=${xs.shape}, ys=${ys.shape}`);log('üéØ Starting classification training loop...');try{await model.fit(xs,ys,{epochs:epochs,batchSize:batchSize,shuffle:!0,callbacks:{onEpochBegin:async ep=>{document.getElementById('currentEpoch').textContent=ep+1;await tf.nextFrame();},onEpochEnd:(ep,logs)=>{if(!isTraining)model.stopTraining=!0;const p=((ep+1)/epochs)*100;document.getElementById('trainingProgress').style.width=p+'%';document.getElementById('trainingLoss').textContent=logs.loss.toFixed(4);document.getElementById('accuracy').textContent=(logs.acc*100).toFixed(2)+'%';log(`Ep ${ep+1}/${epochs} - Loss: ${logs.loss.toFixed(4)}, Acc: ${(logs.acc*100).toFixed(2)}%`);}}});}finally{tf.dispose([xs,ys]);}if(isTraining&&!(model&&model.stopTraining))log('‚úÖ Classification training completed!');}
        async function prepareClassificationData(trainingImages,numModelOutputClasses){const ts=await Promise.all(trainingImages.map(async iD=>{if(!iD.annotations||iD.annotations.length===0)return null;const iE=new Image();iE.src=iD.src;await new Promise(r=>iE.onload=r);return tf.tidy(()=>{const iT=tf.browser.fromPixels(iE).resizeNearestNeighbor([IMG_HEIGHT,IMG_WIDTH]).toFloat().div(255.0);const l=iD.annotations[0].label,cId=classMap[l];if(cId===undefined){console.warn(`Label "${l}" not in classMap for ${iD.name}. Skipping.`);iT.dispose();return null;}
        const lT=tf.oneHot(tf.tensor1d([cId],'int32'),numModelOutputClasses).squeeze();return{imageTensor:iT,labelTensor:lT};});}));const vT=ts.filter(t=>t!==null);if(vT.length===0)return{};const xs=tf.stack(vT.map(t=>t.imageTensor)),ys=tf.stack(vT.map(t=>t.labelTensor));vT.forEach(t=>{if(t){t.imageTensor.dispose();t.labelTensor.dispose();}});return{xs,ys};}
        function createObjectDetectionModel(numModelOutputClasses){const i=tf.input({shape:[IMG_HEIGHT,IMG_WIDTH,3]});let x=tf.layers.conv2d({filters:16,kernelSize:3,activation:'relu',padding:'same'}).apply(i);x=tf.layers.maxPooling2d({poolSize:2}).apply(x);x=tf.layers.conv2d({filters:32,kernelSize:3,activation:'relu',padding:'same'}).apply(x);x=tf.layers.maxPooling2d({poolSize:2}).apply(x);x=tf.layers.conv2d({filters:64,kernelSize:3,activation:'relu',padding:'same'}).apply(x);x=tf.layers.maxPooling2d({poolSize:2}).apply(x);x=tf.layers.flatten().apply(x);x=tf.layers.dense({units:128,activation:'relu'}).apply(x);x=tf.layers.dropout({rate:0.2}).apply(x);
        const bO=tf.layers.dense({units:4,activation:'sigmoid',name:'bbox_output'}).apply(x);const cO=tf.layers.dense({units:numModelOutputClasses,activation:'softmax',name:'class_output'}).apply(x);return tf.model({inputs:i,outputs:[bO,cO]});}
        let currentLocLoss=0,currentClassLoss=0;
        async function trainSimpleDetectionModel(epochs,learningRate,batchSize,trainingImages,numModelOutputClasses){log('üîß Building Simple Object Detection model...');model=createObjectDetectionModel(numModelOutputClasses);const opt=tf.train.adam(learningRate);log('üìä Preparing all detection data...');const{allXs,allYs}=await prepareDetectionData(trainingImages,numModelOutputClasses);if(!allXs||allXs.shape[0]===0){log("‚ùå No valid data for detection training.");tf.dispose([allXs,allYs?.trueBoxes,allYs?.trueClasses]);return;}
        log(`Prepared detection data: Xs shape: ${allXs.shape}, Ys Boxes: ${allYs.trueBoxes.shape}, Ys Classes: ${allYs.trueClasses.shape}`);log('üéØ Starting Detection training loop...');for(let ep=0;ep<epochs;ep++){if(!isTraining){log("Training stopped.");break;}document.getElementById('currentEpoch').textContent=ep+1;let eTL=0,eLL=0,eCL=0,nB=0;const nS=allXs.shape[0],sI=tf.util.createShuffledIndices(nS);
        for(let i=0;i<nS;i+=batchSize){if(!isTraining)break;const bS=i,bE=Math.min(i+batchSize,nS),aBS=bE-bS,bIA=Array.from(sI.slice(bS,bE));if(aBS===0)continue;const lT=tf.tidy(()=>{const xB=tf.gather(allXs,tf.tensor1d(bIA,'int32')),yBTB=tf.gather(allYs.trueBoxes,tf.tensor1d(bIA,'int32')),yBTC=tf.gather(allYs.trueClasses,tf.tensor1d(bIA,'int32'));const{value,grads}=opt.computeGradients(()=>{const pY=model.apply(xB),pB=pY[0],pC=pY[1];const lL=tf.losses.meanSquaredError(yBTB,pB).mean(),cL=tf.losses.categoricalCrossentropy(yBTC,pC).mean();currentLocLoss=lL.dataSync()[0];currentClassLoss=cL.dataSync()[0];return tf.add(lL.mul(0.5),cL.mul(0.5));},model.trainableWeights);opt.applyGradients(grads);tf.dispose(grads);return{totalLoss:value,locLoss:tf.scalar(currentLocLoss),classLoss:tf.scalar(currentClassLoss)};});
        eTL+=lT.totalLoss.dataSync()[0];eLL+=lT.locLoss.dataSync()[0];eCL+=lT.classLoss.dataSync()[0];tf.dispose(lT);nB++;await tf.nextFrame();}
        tf.dispose(sI);if(nB>0){const avgEL=eTL/nB,avgELL=eLL/nB,avgECL=eCL/nB;document.getElementById('trainingLoss').textContent=avgEL.toFixed(4);document.getElementById('locLossDisplay').textContent=`Loc: ${avgELL.toFixed(4)}`;document.getElementById('classLossDisplay').textContent=`Class: ${avgECL.toFixed(4)}`;document.getElementById('accuracy').textContent=avgEL.toFixed(4);log(`Ep ${ep+1}/${epochs} - AvgLoss: ${avgEL.toFixed(4)} (Loc: ${avgELL.toFixed(4)}, Class: ${avgECL.toFixed(4)})`);}
        const prog=((ep+1)/epochs)*100;document.getElementById('trainingProgress').style.width=prog+'%';if(!isTraining)break;}
        tf.dispose([allXs,allYs.trueBoxes,allYs.trueClasses]);if(isTraining&&!(model&&model.stopTraining))log('‚úÖ Simple Detection training completed!');}
        async function prepareDetectionData(trainingImages,numModelOutputClasses){const iT=[],tB=[],tC=[];let cnt=0;for(const iD of trainingImages){if(!iD.annotations||iD.annotations.length===0)continue;const iE=new Image();iE.src=iD.src;await new Promise(r=>iE.onload=r);const oIT=tf.tidy(()=>tf.browser.fromPixels(iE).toFloat().div(255.0)),rIT=tf.image.resizeNearestNeighbor(oIT,[IMG_HEIGHT,IMG_WIDTH]);oIT.dispose();
        for(const ann of iD.annotations){if(!iD.originalWidth||!iD.originalHeight){log(`Skip ann for ${iD.name} (no dims).`);continue;}iT.push(rIT.clone());const nX=ann.x/iD.originalWidth,nY=ann.y/iD.originalHeight,nW=ann.width/iD.originalWidth,nH=ann.height/iD.originalHeight;tB.push(tf.tensor1d([nX,nY,nW,nH]));const cId=classMap[ann.label];if(cId===undefined){console.warn(`Label "${ann.label}" not in classMap for ${iD.name}.`);iT.pop().dispose();tB.pop().dispose();continue;}
        tC.push(tf.oneHot(tf.tensor1d([cId],'int32'),numModelOutputClasses).squeeze());cnt++;}rIT.dispose();}
        if(iT.length===0)return{};log(`Processed ${cnt} anns into ${iT.length} detection samples.`);const aX=tf.stack(iT),aY={trueBoxes:tf.stack(tB),trueClasses:tf.stack(tC)};iT.forEach(t=>t.dispose());tB.forEach(t=>t.dispose());tC.forEach(t=>t.dispose());return{allXs:aX,allYs:aY};}
        function stopTraining(){isTraining=!1;if(model&&typeof model.stopTraining==='boolean')model.stopTraining=!0;log('‚èπÔ∏è Training stop requested.');document.getElementById('trainBtn').disabled=!1;document.getElementById('stopBtn').disabled=!0;}
        function log(msg){const lD=document.getElementById('trainingLog'),ts=new Date().toLocaleTimeString([],{hour:'2-digit',minute:'2-digit',second:'2-digit'}),p=document.createElement('p');p.textContent=`[${ts}] ${msg}`;lD.appendChild(p);lD.scrollTop=lD.scrollHeight;}
        async function exportModel(fmt){if(!model){alert('No model!');return;}const s=document.getElementById('exportStatus');s.innerHTML='Processing...';try{if(fmt==='tensorflow'){await model.save('downloads://local-ml-model');s.innerHTML='‚úÖ TF.js Model Exported!';}else if(fmt==='weights'){const w=model.getWeights();const wd=[];for(const t of w){wd.push(Array.from(await t.data()));t.dispose();}downloadBlob(new Blob([JSON.stringify(wd,null,2)],{type:'application/json'}),'model-weights.json');s.innerHTML='‚úÖ Weights Exported!';}else{s.innerHTML='üöß ONNX Placeholder.';}}catch(e){s.innerHTML=`‚ùå Export Failed: ${e.message}`;log(e.message);console.error(e);}}
        function exportDataset(){const dE={images:images.map(i=>({id:i.id,name:i.name,originalWidth:i.originalWidth,originalHeight:i.originalHeight,annotations:i.annotations.map(a=>({label:a.label,classId:classMap[a.label],x:a.x,y:a.y,width:a.width,height:a.height}))})),class_map:classMap,metadata:{totalImages:images.length,labeledImages:images.filter(i=>i.annotations?.length>0).length,totalAnnotations:images.reduce((s,i)=>s+(i.annotations?.length||0),0),exportDate:new Date().toISOString()}};const b=new Blob([JSON.stringify(dE,null,2)],{type:'application/json'});downloadBlob(b,'local-ml-dataset.json');document.getElementById('exportStatus').innerHTML='‚úÖ Dataset Exported!';}
        function downloadBlob(b,fN){const u=URL.createObjectURL(b),a=document.createElement('a');a.style.display='none';a.href=u;a.download=fN;document.body.appendChild(a);a.click();URL.revokeObjectURL(u);a.remove();}
        function switchTab(ev,tN){document.querySelectorAll('.tab-content').forEach(c=>c.classList.remove('active'));document.querySelectorAll('.tab').forEach(t=>t.classList.remove('active'));document.getElementById(tN).classList.add('active');const tB=ev?ev.target:document.querySelector(`.tab[onclick*="'${tN}'"]`);if(tB)tB.classList.add('active');if(tN==='labeling')loadImageForLabeling();updateTrainingUI();}
        document.addEventListener('DOMContentLoaded',()=>{log('üéâ Platform Ready!');updateTrainingUI();try{const sI=localStorage.getItem('ml_trainer_images_v2'),sCM=localStorage.getItem('ml_trainer_classMap_v2'),sNCI=localStorage.getItem('ml_trainer_nextClassId_v2');if(sI)images=JSON.parse(sI);if(sCM)classMap=JSON.parse(sCM);if(sNCI)nextClassId=parseInt(sNCI);}catch(e){log(`LocalStorage Load Err: ${e.message}`);images=[];classMap={};nextClassId=0;}updateDatasetStats();renderImageGrid();if(images.length>0)loadImageForLabeling();});
        setInterval(()=>{if(images.length>0){try{localStorage.setItem('ml_trainer_images_v2',JSON.stringify(images));localStorage.setItem('ml_trainer_classMap_v2',JSON.stringify(classMap));localStorage.setItem('ml_trainer_nextClassId_v2',nextClassId.toString());}catch(e){log("Autosave err.");}}},15000);
        ['dragenter','dragover','dragleave','drop'].forEach(eN=>document.addEventListener(eN,eP=>{eP.preventDefault();eP.stopPropagation();}));
        document.addEventListener('keydown',eK=>{const aT=document.querySelector('.tab-content.active');if(aT&&aT.id==='labeling'){if(document.activeElement.tagName==='INPUT'||document.activeElement.tagName==='TEXTAREA')return;if(eK.key==='ArrowRight'){eK.preventDefault();nextImage();}else if(eK.key==='ArrowLeft'){eK.preventDefault();prevImage();}}});
    </script>
</body>
</html>
